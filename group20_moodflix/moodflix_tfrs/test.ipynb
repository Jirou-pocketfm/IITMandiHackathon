{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 20:14:33.679322: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-03 20:14:33.708323: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-03 20:14:33.708347: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-03 20:14:33.708374: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-03 20:14:33.714144: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-03 20:14:33.715318: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-03 20:14:34.351244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'Guardians of the Galaxy'>, 'Genre': <tf.Tensor: shape=(), dtype=string, numpy=b'Action'>, 'Year': <tf.Tensor: shape=(), dtype=int64, numpy=2014>, 'Runtime': <tf.Tensor: shape=(), dtype=int64, numpy=121>, 'Rating': <tf.Tensor: shape=(), dtype=float64, numpy=8.1>, 'Metascore': <tf.Tensor: shape=(), dtype=float64, numpy=76.0>, 'Description': <tf.Tensor: shape=(), dtype=string, numpy=b'A group of intergalactic criminals are forced to work together to stop a fanatical warrior from taking control of the universe.'>}\n",
      "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'Guardians of the Galaxy'>, 'Genre': <tf.Tensor: shape=(), dtype=string, numpy=b'Adventure'>, 'Year': <tf.Tensor: shape=(), dtype=int64, numpy=2014>, 'Runtime': <tf.Tensor: shape=(), dtype=int64, numpy=121>, 'Rating': <tf.Tensor: shape=(), dtype=float64, numpy=8.1>, 'Metascore': <tf.Tensor: shape=(), dtype=float64, numpy=76.0>, 'Description': <tf.Tensor: shape=(), dtype=string, numpy=b'A group of intergalactic criminals are forced to work together to stop a fanatical warrior from taking control of the universe.'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 20:14:34.982912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-03 20:14:35.005181: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from dataloader import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset()\n",
    "movies = dataset.batch(8)\n",
    "\n",
    "unique_titles = set()\n",
    "unique_genres = set()\n",
    "\n",
    "for batch in movies:\n",
    "    # print(batch)\n",
    "    titles = batch['Title'].numpy()  # tensor of strings\n",
    "    genres = batch['Genre'].numpy()\n",
    "    unique_titles.update(titles)\n",
    "    unique_genres.update(genres)\n",
    "\n",
    "unique_titles = np.array(list(unique_titles))\n",
    "unique_genres = np.array(list(unique_genres))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = dataset.map(lambda x: x[\"Title\"])\n",
    "descriptions = dataset.map(lambda x: x[\"Description\"])\n",
    "years = np.concatenate(list(dataset.map(lambda x: x[\"Year\"]).batch(100)))\n",
    "ratings = np.concatenate(list(dataset.map(lambda x: x[\"Rating\"]).batch(100)))\n",
    "metascores = np.concatenate(list(dataset.map(lambda x: x[\"Metascore\"]).batch(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.1, 8.1, 8.1, 7. , 7. , 7. , 7.3, 7.3, 7.2, 7.2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76., 76., 76., 65., 65., 65., 62., 62., 59., 59.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metascores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_year = years.max()\n",
    "min_year = years.min()\n",
    "\n",
    "year_buckets = np.arange(\n",
    "    min_year, max_year, 2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10000\n",
    "\n",
    "    self.genre_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_genres, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_genres) + 1, 32),\n",
    "    ])\n",
    "    self.year_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.Discretization(year_buckets.tolist()),\n",
    "        tf.keras.layers.Embedding(len(year_buckets) + 1, 32),\n",
    "    ])\n",
    "    self.normalized_rating = tf.keras.layers.Normalization(\n",
    "        axis=None\n",
    "    )\n",
    "    # self.normalized_metascore = tf.keras.layers.Normalization(\n",
    "    #     axis=None\n",
    "    # )\n",
    "    self.desc_vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens)\n",
    "\n",
    "    self.desc_embedding = tf.keras.Sequential([\n",
    "      self.desc_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "\n",
    "    self.desc_vectorizer.adapt(descriptions)\n",
    "    self.normalized_rating.adapt(ratings)\n",
    "    # self.normalized_metascore.adapt(metascores)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Take the input dictionary, pass it through each input layer,\n",
    "    # and concatenate the result.\n",
    "    return tf.concat([\n",
    "        self.genre_embedding(inputs[\"Genre\"]),\n",
    "        self.year_embedding(inputs[\"Year\"]),\n",
    "        self.desc_embedding(inputs[\"Description\"]),\n",
    "        tf.reshape(self.normalized_rating(inputs[\"Rating\"]), (-1, 1)),\n",
    "        # tf.reshape(self.normalized_metascore(inputs[\"Metascore\"]), (-1, 1)),\n",
    "    ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "  \"\"\"Model for encoding user queries.\"\"\"\n",
    "\n",
    "  def __init__(self, layer_sizes):\n",
    "    \"\"\"Model for encoding user queries.\n",
    "\n",
    "    Args:\n",
    "      layer_sizes:\n",
    "        A list of integers where the i-th entry represents the number of units\n",
    "        the i-th layer contains.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    # We first use the user model for generating embeddings.\n",
    "    self.embedding_model = UserModel()\n",
    "\n",
    "    # Then construct the layers.\n",
    "    self.dense_layers = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(layer_sizes[0])\n",
    "    ])\n",
    "\n",
    "    # self.dense_layers.build((None, 66))\n",
    "    # dummy_input = tf.random.uniform((1, 66))\n",
    "    # _ = self.dense_layers(dummy_input)\n",
    "\n",
    "    # Use the ReLU activation for all but the last layer.\n",
    "    for layer_size in layer_sizes[:-1]:\n",
    "      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "    # No activation for the last layer.\n",
    "    for layer_size in layer_sizes[-1:]:\n",
    "      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "\n",
    "  def call(self, inputs):\n",
    "    feature_embedding = self.embedding_model(inputs)\n",
    "    return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "\n",
    "    self.title_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "          vocabulary=unique_titles,mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_titles) + 1, 32)\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens)\n",
    "\n",
    "    self.title_text_embedding = tf.keras.Sequential([\n",
    "      self.title_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer.adapt(movies)\n",
    "\n",
    "  def call(self, titles):\n",
    "    return tf.concat([\n",
    "        self.title_embedding(titles),\n",
    "        self.title_text_embedding(titles),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "  \"\"\"Model for encoding movies.\"\"\"\n",
    "\n",
    "  def __init__(self, layer_sizes):\n",
    "    \"\"\"Model for encoding movies.\n",
    "\n",
    "    Args:\n",
    "      layer_sizes:\n",
    "        A list of integers where the i-th entry represents the number of units\n",
    "        the i-th layer contains.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding_model = MovieModel()\n",
    "\n",
    "    # Then construct the layers.\n",
    "    self.dense_layers = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(layer_sizes[0])\n",
    "    ])\n",
    "\n",
    "    # self.dense_layers.build((None, 64))\n",
    "    # # Force weight creation\n",
    "    # dummy_input = tf.random.uniform((1, 64))\n",
    "    # _ = self.dense_layers(dummy_input)\n",
    "\n",
    "    # Use the ReLU activation for all but the last layer.\n",
    "    for layer_size in layer_sizes[:-1]:\n",
    "      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "    # No activation for the last layer.\n",
    "    for layer_size in layer_sizes[-1:]:\n",
    "      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "\n",
    "    # embedding_dim = 32\n",
    "    # self.dense_layers.build([None, embedding_dim])\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "    feature_embedding = self.embedding_model(inputs)\n",
    "    return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, layer_sizes_query, layer_sizes_cand):\n",
    "    super().__init__()\n",
    "    self.query_model = QueryModel(layer_sizes_query)\n",
    "    self.candidate_model = CandidateModel(layer_sizes_cand)\n",
    "    # self.query_model = UserModel()\n",
    "    # self.candidate_model = MovieModel()\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(32).map(self.candidate_model),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    query_embeddings = self.query_model({\n",
    "        \"Genre\": features[\"Genre\"],\n",
    "        \"Year\": features[\"Year\"],\n",
    "        \"Rating\": features[\"Rating\"],\n",
    "        \"Metascore\": features[\"Metascore\"],\n",
    "        \"Description\": features[\"Description\"]\n",
    "    })\n",
    "    print(\"Query_emb\", query_embeddings)\n",
    "    movie_embeddings = self.candidate_model(features[\"Title\"])\n",
    "    print(\"Movie_emb\", movie_embeddings)\n",
    "\n",
    "    return self.task(\n",
    "        query_embeddings, movie_embeddings, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = dataset.shuffle(1000, seed=42, reshuffle_each_iteration=False)\n",
    "test = shuffled.take(100)\n",
    "cached_train = dataset.batch(32).cache()\n",
    "cached_test = test.batch(32).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds_students/anaconda3/envs/moodfli/lib/python3.10/site-packages/numpy/core/numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "cand_model = CandidateModel([32])\n",
    "quer_model = QueryModel([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature:  tf.Tensor(\n",
      "[[ 1.0444511e-02 -3.5711028e-02  1.5444588e-02 ... -3.9134803e-03\n",
      "   6.8814028e-03 -2.2315037e+00]\n",
      " [ 1.2819912e-02 -1.5509836e-03  3.2763369e-03 ...  1.5111574e-03\n",
      "   4.6860855e-03 -9.2937207e-01]\n",
      " [-9.1033578e-03 -1.6571712e-02  2.1583501e-02 ... -8.7014064e-03\n",
      "   5.3433847e-04 -4.9532822e-01]\n",
      " ...\n",
      " [ 8.6917505e-03  4.2821094e-04 -2.1085966e-02 ... -8.1995176e-03\n",
      "   2.4131734e-03  1.3493577e+00]\n",
      " [ 1.9613612e-02 -3.2651234e-02  1.0578789e-02 ...  1.2999254e-03\n",
      "   6.9552218e-03  5.8978128e-01]\n",
      " [ 8.6917505e-03  4.2821094e-04 -2.1085966e-02 ...  7.0575433e-04\n",
      "   3.1685568e-03  1.3493577e+00]], shape=(32, 97), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.07572958 -0.34633428 -0.60807157 ...  0.29320794  0.12286784\n",
      "  -0.48907983]\n",
      " [-0.0369146  -0.1526255  -0.22835782 ...  0.10904159  0.02482696\n",
      "  -0.1893226 ]\n",
      " [ 0.01591535 -0.06743775 -0.15524805 ...  0.06287812  0.02239685\n",
      "  -0.11111928]\n",
      " ...\n",
      " [ 0.071205    0.26479918  0.3562327  ... -0.14463918 -0.0842466\n",
      "   0.30393445]\n",
      " [ 0.02994398  0.08889621  0.12866193 ... -0.09772241 -0.03635474\n",
      "   0.15206817]\n",
      " [ 0.05112373  0.24422124  0.3412891  ... -0.15312296 -0.12341686\n",
      "   0.34153065]], shape=(32, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for row in cached_test.take(1):\n",
    "    print(quer_model({\n",
    "        \"Genre\": row[\"Genre\"],\n",
    "        \"Year\": row[\"Year\"],\n",
    "        \"Rating\": row[\"Rating\"],\n",
    "        \"Metascore\": row[\"Metascore\"],\n",
    "        \"Description\": row[\"Description\"]\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds_students/anaconda3/envs/moodfli/lib/python3.10/site-packages/numpy/core/numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Query_emb Tensor(\"query_model_10/sequential_75/dense_42/BiasAdd:0\", shape=(None, 32), dtype=float32)\n",
      "Movie_emb Tensor(\"candidate_model_11/sequential_78/dense_44/BiasAdd:0\", shape=(None, 32), dtype=float32)\n",
      "Query_emb Tensor(\"query_model_10/sequential_75/dense_42/BiasAdd:0\", shape=(None, 32), dtype=float32)\n",
      "Movie_emb Tensor(\"candidate_model_11/sequential_78/dense_44/BiasAdd:0\", shape=(None, 32), dtype=float32)\n",
      "80/80 [==============================] - 1s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 110.3161 - regularization_loss: 0.0000e+00 - total_loss: 110.3161\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 103.3832 - regularization_loss: 0.0000e+00 - total_loss: 103.3832\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 96.0921 - regularization_loss: 0.0000e+00 - total_loss: 96.0921\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 92.4779 - regularization_loss: 0.0000e+00 - total_loss: 92.4779\n",
      "Epoch 5/200\n",
      "69/80 [========================>.....] - ETA: 0s - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 87.6509 - regularization_loss: 0.0000e+00 - total_loss: 87.6509Query_emb Tensor(\"query_model_10/sequential_75/dense_42/BiasAdd:0\", shape=(None, 32), dtype=float32)\n",
      "Movie_emb Tensor(\"candidate_model_11/sequential_78/dense_44/BiasAdd:0\", shape=(None, 32), dtype=float32)\n",
      "80/80 [==============================] - 1s 8ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 86.8527 - regularization_loss: 0.0000e+00 - total_loss: 86.8527 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0100 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.0700 - val_factorized_top_k/top_100_categorical_accuracy: 0.1900 - val_loss: 3.7123 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.7123\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 76.6283 - regularization_loss: 0.0000e+00 - total_loss: 76.6283\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 1ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 71.9266 - regularization_loss: 0.0000e+00 - total_loss: 71.9266\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 69.2031 - regularization_loss: 0.0000e+00 - total_loss: 69.2031\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 1ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 63.8283 - regularization_loss: 0.0000e+00 - total_loss: 63.8283\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 60.2092 - regularization_loss: 0.0000e+00 - total_loss: 60.2092 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0100 - val_factorized_top_k/top_50_categorical_accuracy: 0.1300 - val_factorized_top_k/top_100_categorical_accuracy: 0.2200 - val_loss: 4.9678 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.9678\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 58.7677 - regularization_loss: 0.0000e+00 - total_loss: 58.7677\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 56.0864 - regularization_loss: 0.0000e+00 - total_loss: 56.0864\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 53.4641 - regularization_loss: 0.0000e+00 - total_loss: 53.4641\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51.2073 - regularization_loss: 0.0000e+00 - total_loss: 51.2073\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49.7224 - regularization_loss: 0.0000e+00 - total_loss: 49.7224 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0100 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.0800 - val_factorized_top_k/top_100_categorical_accuracy: 0.2200 - val_loss: 4.3145 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.3145\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48.4035 - regularization_loss: 0.0000e+00 - total_loss: 48.4035\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 46.9085 - regularization_loss: 0.0000e+00 - total_loss: 46.9085\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 45.6254 - regularization_loss: 0.0000e+00 - total_loss: 45.6254\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43.6109 - regularization_loss: 0.0000e+00 - total_loss: 43.6109\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 42.5032 - regularization_loss: 0.0000e+00 - total_loss: 42.5032 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0100 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.1500 - val_factorized_top_k/top_100_categorical_accuracy: 0.2700 - val_loss: 3.8960 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.8960\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 41.4853 - regularization_loss: 0.0000e+00 - total_loss: 41.4853\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 40.5091 - regularization_loss: 0.0000e+00 - total_loss: 40.5091\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 39.5399 - regularization_loss: 0.0000e+00 - total_loss: 39.5399\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 38.6823 - regularization_loss: 0.0000e+00 - total_loss: 38.6823\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 37.5779 - regularization_loss: 0.0000e+00 - total_loss: 37.5779 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.1800 - val_factorized_top_k/top_100_categorical_accuracy: 0.3500 - val_loss: 5.8114 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.8114\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 3ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 37.1701 - regularization_loss: 0.0000e+00 - total_loss: 37.1701\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 3ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 36.2698 - regularization_loss: 0.0000e+00 - total_loss: 36.2698\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 35.7645 - regularization_loss: 0.0000e+00 - total_loss: 35.7645\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 34.9899 - regularization_loss: 0.0000e+00 - total_loss: 34.9899\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 34.3565 - regularization_loss: 0.0000e+00 - total_loss: 34.3565 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0100 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.1700 - val_factorized_top_k/top_100_categorical_accuracy: 0.3600 - val_loss: 2.7081 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.7081\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 3ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33.8820 - regularization_loss: 0.0000e+00 - total_loss: 33.8820\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33.5162 - regularization_loss: 0.0000e+00 - total_loss: 33.5162\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33.0189 - regularization_loss: 0.0000e+00 - total_loss: 33.0189\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32.6912 - regularization_loss: 0.0000e+00 - total_loss: 32.6912\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32.1529 - regularization_loss: 0.0000e+00 - total_loss: 32.1529 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.3900 - val_loss: 5.1739 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.1739\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32.0694 - regularization_loss: 0.0000e+00 - total_loss: 32.0694\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 31.8217 - regularization_loss: 0.0000e+00 - total_loss: 31.8217\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 31.5934 - regularization_loss: 0.0000e+00 - total_loss: 31.5934\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 1ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 31.3270 - regularization_loss: 0.0000e+00 - total_loss: 31.3270\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 31.2867 - regularization_loss: 0.0000e+00 - total_loss: 31.2867 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.2000 - val_factorized_top_k/top_100_categorical_accuracy: 0.3900 - val_loss: 4.2023 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.2023\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 31.0510 - regularization_loss: 0.0000e+00 - total_loss: 31.0510\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.9882 - regularization_loss: 0.0000e+00 - total_loss: 30.9882\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.7602 - regularization_loss: 0.0000e+00 - total_loss: 30.7602\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 1ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.6433 - regularization_loss: 0.0000e+00 - total_loss: 30.6433\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.6574 - regularization_loss: 0.0000e+00 - total_loss: 30.6574 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4000 - val_loss: 4.1970 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.1970\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.7256 - regularization_loss: 0.0000e+00 - total_loss: 30.7256\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.5088 - regularization_loss: 0.0000e+00 - total_loss: 30.5088\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.4381 - regularization_loss: 0.0000e+00 - total_loss: 30.4381\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.4084 - regularization_loss: 0.0000e+00 - total_loss: 30.4084\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.3402 - regularization_loss: 0.0000e+00 - total_loss: 30.3402 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2400 - val_factorized_top_k/top_100_categorical_accuracy: 0.4000 - val_loss: 5.0674 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.0674\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.3533 - regularization_loss: 0.0000e+00 - total_loss: 30.3533\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.2797 - regularization_loss: 0.0000e+00 - total_loss: 30.2797\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.2664 - regularization_loss: 0.0000e+00 - total_loss: 30.2664\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.2584 - regularization_loss: 0.0000e+00 - total_loss: 30.2584\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.2888 - regularization_loss: 0.0000e+00 - total_loss: 30.2888 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0100 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4000 - val_loss: 4.8097 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.8097\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.2086 - regularization_loss: 0.0000e+00 - total_loss: 30.2086\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1952 - regularization_loss: 0.0000e+00 - total_loss: 30.1952\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1808 - regularization_loss: 0.0000e+00 - total_loss: 30.1808\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1703 - regularization_loss: 0.0000e+00 - total_loss: 30.1703\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1595 - regularization_loss: 0.0000e+00 - total_loss: 30.1595 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4000 - val_loss: 5.2012 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.2012\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 3ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1506 - regularization_loss: 0.0000e+00 - total_loss: 30.1506\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1423 - regularization_loss: 0.0000e+00 - total_loss: 30.1423\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1351 - regularization_loss: 0.0000e+00 - total_loss: 30.1351\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1286 - regularization_loss: 0.0000e+00 - total_loss: 30.1286\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1229 - regularization_loss: 0.0000e+00 - total_loss: 30.1229 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.2300 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 5.3210 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.3210\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1177 - regularization_loss: 0.0000e+00 - total_loss: 30.1177\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1135 - regularization_loss: 0.0000e+00 - total_loss: 30.1135\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1089 - regularization_loss: 0.0000e+00 - total_loss: 30.1089\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1056 - regularization_loss: 0.0000e+00 - total_loss: 30.1056\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.1001 - regularization_loss: 0.0000e+00 - total_loss: 30.1001 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2300 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 5.5980 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.5980\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0960 - regularization_loss: 0.0000e+00 - total_loss: 30.0960\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0905 - regularization_loss: 0.0000e+00 - total_loss: 30.0905\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0863 - regularization_loss: 0.0000e+00 - total_loss: 30.0863\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0827 - regularization_loss: 0.0000e+00 - total_loss: 30.0827\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0796 - regularization_loss: 0.0000e+00 - total_loss: 30.0796 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2300 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 5.6455 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.6455\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 3ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0768 - regularization_loss: 0.0000e+00 - total_loss: 30.0768\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0741 - regularization_loss: 0.0000e+00 - total_loss: 30.0741\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0716 - regularization_loss: 0.0000e+00 - total_loss: 30.0716\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0692 - regularization_loss: 0.0000e+00 - total_loss: 30.0692\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0670 - regularization_loss: 0.0000e+00 - total_loss: 30.0670 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2300 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 5.7642 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.7642\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0648 - regularization_loss: 0.0000e+00 - total_loss: 30.0648\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0628 - regularization_loss: 0.0000e+00 - total_loss: 30.0628\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0609 - regularization_loss: 0.0000e+00 - total_loss: 30.0609\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0591 - regularization_loss: 0.0000e+00 - total_loss: 30.0591\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0573 - regularization_loss: 0.0000e+00 - total_loss: 30.0573 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.2300 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 5.8673 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.8673\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0557 - regularization_loss: 0.0000e+00 - total_loss: 30.0557\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0541 - regularization_loss: 0.0000e+00 - total_loss: 30.0541\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0526 - regularization_loss: 0.0000e+00 - total_loss: 30.0526\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0512 - regularization_loss: 0.0000e+00 - total_loss: 30.0512\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0498 - regularization_loss: 0.0000e+00 - total_loss: 30.0498 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0100 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 5.9604 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.9604\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0485 - regularization_loss: 0.0000e+00 - total_loss: 30.0485\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0472 - regularization_loss: 0.0000e+00 - total_loss: 30.0472\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0460 - regularization_loss: 0.0000e+00 - total_loss: 30.0460\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0449 - regularization_loss: 0.0000e+00 - total_loss: 30.0449\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0438 - regularization_loss: 0.0000e+00 - total_loss: 30.0438 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.0463 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.0463\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0427 - regularization_loss: 0.0000e+00 - total_loss: 30.0427\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0417 - regularization_loss: 0.0000e+00 - total_loss: 30.0417\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0407 - regularization_loss: 0.0000e+00 - total_loss: 30.0407\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0398 - regularization_loss: 0.0000e+00 - total_loss: 30.0398\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0388 - regularization_loss: 0.0000e+00 - total_loss: 30.0388 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.1248 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.1248\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0380 - regularization_loss: 0.0000e+00 - total_loss: 30.0380\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0371 - regularization_loss: 0.0000e+00 - total_loss: 30.0371\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0363 - regularization_loss: 0.0000e+00 - total_loss: 30.0363\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0355 - regularization_loss: 0.0000e+00 - total_loss: 30.0355\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0348 - regularization_loss: 0.0000e+00 - total_loss: 30.0348 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0400 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.1972 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.1972\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 1ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0341 - regularization_loss: 0.0000e+00 - total_loss: 30.0341\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0334 - regularization_loss: 0.0000e+00 - total_loss: 30.0334\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0327 - regularization_loss: 0.0000e+00 - total_loss: 30.0327\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0320 - regularization_loss: 0.0000e+00 - total_loss: 30.0320\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0314 - regularization_loss: 0.0000e+00 - total_loss: 30.0314 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.2646 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.2646\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0308 - regularization_loss: 0.0000e+00 - total_loss: 30.0308\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0302 - regularization_loss: 0.0000e+00 - total_loss: 30.0302\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0296 - regularization_loss: 0.0000e+00 - total_loss: 30.0296\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0290 - regularization_loss: 0.0000e+00 - total_loss: 30.0290\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0285 - regularization_loss: 0.0000e+00 - total_loss: 30.0285 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.3274 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.3274\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0280 - regularization_loss: 0.0000e+00 - total_loss: 30.0280\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0275 - regularization_loss: 0.0000e+00 - total_loss: 30.0275\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0270 - regularization_loss: 0.0000e+00 - total_loss: 30.0270\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0265 - regularization_loss: 0.0000e+00 - total_loss: 30.0265\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0260 - regularization_loss: 0.0000e+00 - total_loss: 30.0260 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0400 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.3861 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.3861\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0256 - regularization_loss: 0.0000e+00 - total_loss: 30.0256\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0251 - regularization_loss: 0.0000e+00 - total_loss: 30.0251\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0247 - regularization_loss: 0.0000e+00 - total_loss: 30.0247\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0243 - regularization_loss: 0.0000e+00 - total_loss: 30.0243\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0239 - regularization_loss: 0.0000e+00 - total_loss: 30.0239 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0400 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.4415 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.4415\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0235 - regularization_loss: 0.0000e+00 - total_loss: 30.0235\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 1ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0231 - regularization_loss: 0.0000e+00 - total_loss: 30.0231\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0227 - regularization_loss: 0.0000e+00 - total_loss: 30.0227\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0224 - regularization_loss: 0.0000e+00 - total_loss: 30.0224\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0220 - regularization_loss: 0.0000e+00 - total_loss: 30.0220 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.4937 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.4937\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0217 - regularization_loss: 0.0000e+00 - total_loss: 30.0217\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0213 - regularization_loss: 0.0000e+00 - total_loss: 30.0213\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0210 - regularization_loss: 0.0000e+00 - total_loss: 30.0210\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0207 - regularization_loss: 0.0000e+00 - total_loss: 30.0207\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0204 - regularization_loss: 0.0000e+00 - total_loss: 30.0204 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.5432 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.5432\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0201 - regularization_loss: 0.0000e+00 - total_loss: 30.0201\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0198 - regularization_loss: 0.0000e+00 - total_loss: 30.0198\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0195 - regularization_loss: 0.0000e+00 - total_loss: 30.0195\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0192 - regularization_loss: 0.0000e+00 - total_loss: 30.0192\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0189 - regularization_loss: 0.0000e+00 - total_loss: 30.0189 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.5901 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.5901\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0186 - regularization_loss: 0.0000e+00 - total_loss: 30.0186\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0184 - regularization_loss: 0.0000e+00 - total_loss: 30.0184\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0181 - regularization_loss: 0.0000e+00 - total_loss: 30.0181\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0179 - regularization_loss: 0.0000e+00 - total_loss: 30.0179\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0176 - regularization_loss: 0.0000e+00 - total_loss: 30.0176 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.6347 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.6347\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0174 - regularization_loss: 0.0000e+00 - total_loss: 30.0174\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0171 - regularization_loss: 0.0000e+00 - total_loss: 30.0171\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0169 - regularization_loss: 0.0000e+00 - total_loss: 30.0169\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0167 - regularization_loss: 0.0000e+00 - total_loss: 30.0167\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0165 - regularization_loss: 0.0000e+00 - total_loss: 30.0165 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.6771 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.6771\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0162 - regularization_loss: 0.0000e+00 - total_loss: 30.0162\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0160 - regularization_loss: 0.0000e+00 - total_loss: 30.0160\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0158 - regularization_loss: 0.0000e+00 - total_loss: 30.0158\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0156 - regularization_loss: 0.0000e+00 - total_loss: 30.0156\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0154 - regularization_loss: 0.0000e+00 - total_loss: 30.0154 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0400 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.7176 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.7176\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0152 - regularization_loss: 0.0000e+00 - total_loss: 30.0152\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0150 - regularization_loss: 0.0000e+00 - total_loss: 30.0150\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0148 - regularization_loss: 0.0000e+00 - total_loss: 30.0148\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0147 - regularization_loss: 0.0000e+00 - total_loss: 30.0147\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0145 - regularization_loss: 0.0000e+00 - total_loss: 30.0145 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0400 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.7563 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.7563\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0143 - regularization_loss: 0.0000e+00 - total_loss: 30.0143\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0141 - regularization_loss: 0.0000e+00 - total_loss: 30.0141\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0140 - regularization_loss: 0.0000e+00 - total_loss: 30.0140\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0138 - regularization_loss: 0.0000e+00 - total_loss: 30.0138\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0136 - regularization_loss: 0.0000e+00 - total_loss: 30.0136 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0100 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.7934 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.7934\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0135 - regularization_loss: 0.0000e+00 - total_loss: 30.0135\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0133 - regularization_loss: 0.0000e+00 - total_loss: 30.0133\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0131 - regularization_loss: 0.0000e+00 - total_loss: 30.0131\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0130 - regularization_loss: 0.0000e+00 - total_loss: 30.0130\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0128 - regularization_loss: 0.0000e+00 - total_loss: 30.0128 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.8290 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.8290\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 3ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0127 - regularization_loss: 0.0000e+00 - total_loss: 30.0127\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0125 - regularization_loss: 0.0000e+00 - total_loss: 30.0125\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0124 - regularization_loss: 0.0000e+00 - total_loss: 30.0124\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0123 - regularization_loss: 0.0000e+00 - total_loss: 30.0123\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0121 - regularization_loss: 0.0000e+00 - total_loss: 30.0121 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.8632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.8632\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0120 - regularization_loss: 0.0000e+00 - total_loss: 30.0120\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0119 - regularization_loss: 0.0000e+00 - total_loss: 30.0119\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0117 - regularization_loss: 0.0000e+00 - total_loss: 30.0117\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0116 - regularization_loss: 0.0000e+00 - total_loss: 30.0116\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0115 - regularization_loss: 0.0000e+00 - total_loss: 30.0115 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.8957 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.8957\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0114 - regularization_loss: 0.0000e+00 - total_loss: 30.0114\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0112 - regularization_loss: 0.0000e+00 - total_loss: 30.0112\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0111 - regularization_loss: 0.0000e+00 - total_loss: 30.0111\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0110 - regularization_loss: 0.0000e+00 - total_loss: 30.0110\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0109 - regularization_loss: 0.0000e+00 - total_loss: 30.0109 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0400 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.9273 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.9273\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0108 - regularization_loss: 0.0000e+00 - total_loss: 30.0108\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0107 - regularization_loss: 0.0000e+00 - total_loss: 30.0107\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0105 - regularization_loss: 0.0000e+00 - total_loss: 30.0105\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0104 - regularization_loss: 0.0000e+00 - total_loss: 30.0104\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0103 - regularization_loss: 0.0000e+00 - total_loss: 30.0103 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0400 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.9574 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.9574\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0102 - regularization_loss: 0.0000e+00 - total_loss: 30.0102\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 1ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0101 - regularization_loss: 0.0000e+00 - total_loss: 30.0101\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 1ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0100 - regularization_loss: 0.0000e+00 - total_loss: 30.0100\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0099 - regularization_loss: 0.0000e+00 - total_loss: 30.0099\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0098 - regularization_loss: 0.0000e+00 - total_loss: 30.0098 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0400 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 6.9867 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.9867\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0097 - regularization_loss: 0.0000e+00 - total_loss: 30.0097\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0096 - regularization_loss: 0.0000e+00 - total_loss: 30.0096\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0095 - regularization_loss: 0.0000e+00 - total_loss: 30.0095\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0094 - regularization_loss: 0.0000e+00 - total_loss: 30.0094\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 5ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30.0093 - regularization_loss: 0.0000e+00 - total_loss: 30.0093 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0400 - val_factorized_top_k/top_50_categorical_accuracy: 0.2200 - val_factorized_top_k/top_100_categorical_accuracy: 0.4100 - val_loss: 7.0151 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.0151\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "model = MovielensModel([64, 32], [32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))\n",
    "\n",
    "one_layer_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-100 accuracy: 0.41.\n"
     ]
    }
   ],
   "source": [
    "accuracy = one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Dead Awake'], dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Horror'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2016])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([99])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([4.7])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([nan])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'A young woman must save herself and her friends from an ancient evil that stalks its victims through the real-life phenomenon of sleep paralysis.'],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'Office Christmas Party' b'Pet' b'Pet' b'Bride Wars' b'Bride Wars'\n",
      " b\"Mother's Day\" b\"Mother's Day\" b'Folk Hero & Funny Guy' b'Collide'\n",
      " b'Collide']\n",
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'Percy Jackson & the Olympians: The Lightning Thief'],\n",
      "      dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Family'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2010])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([118])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([5.9])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([47.])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b\"A teenager discovers he's the descendant of a Greek god and sets out on an adventure to settle an on-going battle between the gods.\"],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'Adoration' b'Adoration' b'Morgan' b'Morgan' b'Morgan'\n",
      " b'White House Down' b'White House Down' b'White House Down'\n",
      " b\"She's Out of My League\" b\"She's Out of My League\"]\n",
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Trainwreck'], dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Romance'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2015])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([125])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([6.3])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([75.])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'Having thought that monogamy was never possible, a commitment-phobic career woman may have to face her fears when she meets a good guy.'],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'Brimstone' b'Brimstone' b'Brimstone' b'Ballerina' b'Ballerina'\n",
      " b'Ballerina' b'Live by Night' b'Live by Night' b'Tomorrowland'\n",
      " b'Tomorrowland']\n",
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Lobster'], dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Drama'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2015])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([119])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([7.1])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([82.])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'In a dystopian near future, single people, according to the laws of The City, are taken to The Hotel, where they are obliged to find a romantic partner in forty-five days or are transformed into beasts and sent off into The Woods.'],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'Cloverfield' b'Cloverfield' b'Cloverfield' b'Shin Gojira'\n",
      " b'Shin Gojira' b'Shin Gojira'\n",
      " b'Norman: The Moderate Rise and Tragic Fall of a New York Fixer'\n",
      " b'Norman: The Moderate Rise and Tragic Fall of a New York Fixer'\n",
      " b'Anthropoid' b'Anthropoid']\n",
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Twilight Saga: Breaking Dawn - Part 2'], dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Adventure'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2012])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([115])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([5.5])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([52.])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'After the birth of Renesmee, the Cullens gather other vampire clans in order to protect the child from a false allegation that puts the family in front of the Volturi.'],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'Morgan' b'Morgan' b'Morgan' b'Adoration' b'Adoration'\n",
      " b'Office Christmas Party' b'Realive' b'Diary of a Wimpy Kid'\n",
      " b'Diary of a Wimpy Kid' b'The Heat']\n",
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Teenage Mutant Ninja Turtles: Out of the Shadows'], dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Action'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2016])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([112])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([6.])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([40.])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'After facing Shredder, who has joined forces with mad scientist Baxter Stockman and henchmen Bebop and Rocksteady to take over the world, the Turtles must confront an even greater nemesis: the notorious Krang.'],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'Colossal' b'Colossal' b'Colossal' b'Tomorrowland' b'Tomorrowland'\n",
      " b'Tomorrowland' b'Ballerina' b'Ballerina' b'Ballerina' b'The Void']\n",
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Fury'], dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'War'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2014])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([134])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([7.6])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([64.])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'A grizzled tank commander makes tough decisions as he and his crew fight their way across Germany in April, 1945.'],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'Elle' b'Elle' b'Elle'\n",
      " b'Birdman or (The Unexpected Virtue of Ignorance)'\n",
      " b'Birdman or (The Unexpected Virtue of Ignorance)'\n",
      " b'Birdman or (The Unexpected Virtue of Ignorance)'\n",
      " b'The Fault in Our Stars' b'The Fault in Our Stars' b'Dope' b'Dope']\n",
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Iron Man Three'], dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Action'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2013])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([130])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([7.2])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([62.])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b\"When Tony Stark's world is torn apart by a formidable terrorist called the Mandarin, he starts an odyssey of rebuilding and retribution.\"],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'Wanted' b'Wanted' b'Wanted' b'What If' b'What If'\n",
      " b'The Cabin in the Woods' b'Escape Plan' b'Escape Plan' b'Escape Plan'\n",
      " b'The Master']\n",
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'21 Jump Street'], dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Crime'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2012])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([110])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([7.2])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([69.])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'A pair of underachieving cops are sent back to a local high school to blend in and bring down a synthetic drug ring.'],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'The Master' b'The Mist' b'5- 25- 77' b'5- 25- 77' b'Tropic Thunder'\n",
      " b'Tropic Thunder' b'Project X' b'Escape Plan' b'Escape Plan'\n",
      " b'Escape Plan']\n",
      "{'Title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Interstellar'], dtype=object)>, 'Genre': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Sci-Fi'], dtype=object)>, 'Year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2014])>, 'Runtime': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([169])>, 'Rating': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([8.6])>, 'Metascore': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([74.])>, 'Description': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b\"A team of explorers travel through a wormhole in space in an attempt to ensure humanity's survival.\"],\n",
      "      dtype=object)>}\n",
      "Recommendations: [b'I, Daniel Blake' b'Mommy' b'Saving Mr. Banks' b'Saving Mr. Banks'\n",
      " b'Saving Mr. Banks' b'Limitless' b'Limitless' b'Limitless'\n",
      " b'Little Miss Sunshine' b'Little Miss Sunshine']\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.candidate_model)))\n",
    ")\n",
    "\n",
    "# Get recommendations.\n",
    "for row in test.batch(1).take(10):\n",
    "    print(row)\n",
    "    _, titles = index(row)\n",
    "    print(f\"Recommendations: {titles[0, :10]}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5db12884d209488072f0bd62f8cc64cf9bf0c1ae50b857b246ae08481cc688d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('moodfli')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
